{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机森林建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import h5py # 数据存储格式\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预处理部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(data):\n",
    "    # 数据填充\n",
    "    try:\n",
    "        data.loc[data.srch_ci.str.endswith('00'),'srch_ci'] = '2015-12-31'\n",
    "        data['srch_ci'] = data.srch_ci.astype(np.datetime64)\n",
    "        data.loc[data.date_time.str.endswith('00'),'date_time'] = '2015-12-31'\n",
    "        data['date_time'] = data.date_time.astype(np.datetime64)\n",
    "    except:\n",
    "        pass\n",
    "    data.fillna(0, inplace=True) # 缺失值填充， 也可以使用更合理的方式填充，平均值，众数等\n",
    "    \n",
    "    # 新特征添加\n",
    "    # 居住时间\n",
    "    data['srch_duration'] = data.srch_co-data.srch_ci\n",
    "    data['srch_duration'] = data['srch_duration'].apply(lambda td: td/np.timedelta64(1, 'D')) # Datetime转天数\n",
    "    \n",
    "    # 预定到居住的时间，紧急，价格等信息\n",
    "    data['time_to_ci'] = data.srch_ci-data.date_time\n",
    "    data['time_to_ci'] = data['time_to_ci'].apply(lambda td: td/np.timedelta64(1, 'D'))\n",
    "    \n",
    "    # checkin 时间信息\n",
    "    data['ci_month'] = data['srch_ci'].apply(lambda dt: dt.month)\n",
    "    data['ci_day'] = data['srch_ci'].apply(lambda dt: dt.day)\n",
    "    #data['ci_year'] = data['srch_ci'].apply(lambda dt: dt.year)\n",
    "    \n",
    "    # 预定 时间信息， 还可以抽取工作日/周末等信息\n",
    "    data['bk_month'] = data['date_time'].apply(lambda dt: dt.month)\n",
    "    data['bk_day'] = data['date_time'].apply(lambda dt: dt.day)\n",
    "    #data['bk_year'] = data['date_time'].apply(lambda dt: dt.year)\n",
    "    data['bk_hour'] = data['date_time'].apply(lambda dt: dt.hour)\n",
    "    data.drop(['date_time', 'user_id', 'srch_ci', 'srch_co'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('./output/srch_dest_hc_hm_agg.csv'): # 如果跑过直接读\n",
    "    agg1 = pd.read_csv('./output/srch_dest_hc_hm_agg.csv')\n",
    "else:\n",
    "    # 块数据读取  chunksize\n",
    "    reader = pd.read_csv('./input/train.csv', parse_dates=['date_time', 'srch_ci', 'srch_co'], chunksize=200000)  # parse_dates 解析日期\n",
    "    # 聚合操作 分组，聚合预定次数和操作次数\n",
    "    pieces = [chunk.groupby(['srch_destination_id','hotel_country','hotel_market','hotel_cluster'])['is_booking'].agg(['sum','count']) for chunk in reader]\n",
    "    agg = pd.concat(pieces).groupby(level=[0,1,2,3]).sum()\n",
    "    del pieces # 及时删除处理前的数据释放内存\n",
    "    agg.dropna(inplace=True) # 删除nan\n",
    "    agg['sum_and_cnt'] = 0.85*agg['sum'] + 0.15*agg['count'] # 加权聚合\n",
    "    agg = agg.groupby(level=[0,1,2]).apply(lambda x: x.astype(float)/x.sum())\n",
    "    agg.reset_index(inplace=True)\n",
    "    # 数据透视表\n",
    "    agg1 = agg.pivot_table(index=['srch_destination_id','hotel_country','hotel_market'], columns='hotel_cluster', values='sum_and_cnt').reset_index()\n",
    "    agg1.to_csv('./output/srch_dest_hc_hm_agg.csv', index=False)\n",
    "    del agg # 及时删除处理前的数据释放内存\n",
    "#agg1 = agg.set_index(['srch_destination_id','hotel_cluster'])\n",
    "#df1 = train.groupby(['srch_destination_id','hotel_cluster'])['is_booking'].agg(['sum', 'count'])\n",
    "\n",
    "\n",
    "#test = pd.read_csv('./input/test.csv', parse_dates=['date_time', 'srch_ci', 'srch_co'])\n",
    "#test['srch_ci'] = test.apply(lambda row: datetime.datetime.strptime(row['srch_ci']+ ':00:00:00', '%Y-%m-%d:%H:%M:%S'), axis=1)\n",
    "destinations = pd.read_csv('./input/destinations.csv')\n",
    "submission = pd.read_csv('./input/sample_submission.csv')\n",
    "\n",
    "#test = pd.merge(test, destinations, how='left', on='srch_destination_id')\n",
    "#id = test.id\n",
    "#test.drop('id', axis=1, inplace=True)\n",
    "#pre_process(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练过程\n",
    "clf = RandomForestClassifier(n_estimators=0, n_jobs=-1, warm_start=True)\n",
    "count = 0\n",
    "chunksize = 200000\n",
    "reader = pd.read_csv('./input/train.csv', parse_dates=['date_time', 'srch_ci', 'srch_co'], chunksize=chunksize)\n",
    "for chunk in reader:\n",
    "    try:\n",
    "        chunk = chunk[chunk.is_booking==1]\n",
    "        chunk = pd.merge(chunk, destinations, how='left', on='srch_destination_id') # join\n",
    "        chunk = pd.merge(chunk, agg1, how='left', on=['srch_destination_id','hotel_country','hotel_market'])\n",
    "        pre_process(chunk) # 预处理操作\n",
    "        y = chunk.hotel_cluster\n",
    "        chunk.drop(['cnt', 'hotel_cluster', 'is_booking'], axis=1, inplace=True)\n",
    "        \n",
    "        # 训练\n",
    "        if len(y.unique()) == 100:\n",
    "            clf.set_params(n_estimators=clf.n_estimators+1)\n",
    "            clf.fit(chunk, y)\n",
    "        \n",
    "        count = count + chunksize\n",
    "        print('%d rows completed' % count)\n",
    "        if(count/chunksize == 300):\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print('Error: %s' % str(e))\n",
    "        pass\n",
    "\n",
    "# 测试过程\n",
    "count = 0\n",
    "chunksize = 10000\n",
    "preds = np.empty((submission.shape[0],clf.n_classes_))\n",
    "reader = pd.read_csv('./input/test.csv', parse_dates=['date_time', 'srch_ci', 'srch_co'], chunksize=chunksize)\n",
    "for chunk in reader:\n",
    "    chunk = pd.merge(chunk, destinations, how='left', on='srch_destination_id')\n",
    "    chunk = pd.merge(chunk, agg1, how='left', on=['srch_destination_id','hotel_country','hotel_market'])\n",
    "    chunk.drop(['id'], axis=1, inplace=True)\n",
    "    pre_process(chunk)\n",
    "    \n",
    "    pred = clf.predict_proba(chunk)\n",
    "    preds[count:(count + chunk.shape[0]),:] = pred\n",
    "    count = count + chunksize\n",
    "    print('%d rows completed' % count)\n",
    "\n",
    "# 输出预测结果\n",
    "del clf\n",
    "del agg1\n",
    "print('writing current probabilities to file')\n",
    "if os.path.exists('./output/probs/allpreds.h5'):\n",
    "    with h5py.File('./output/probs/allpreds.h5', 'r+') as hf:\n",
    "            print('reading in and combining probabilities')\n",
    "            predslatesthf = hf['preds_latest']\n",
    "            preds += predslatesthf.value\n",
    "            print('writing latest probabilities to file')\n",
    "            predshf[...] = preds\n",
    "else:\n",
    "    with h5py.File('./output/probs/allpreds.h5', 'w') as hf:\n",
    "        print('writing latest probabilities to file')\n",
    "        hf.create_dataset('preds_latest', data=preds)\n",
    "\n",
    "\n",
    "\n",
    "print('generating submission')\n",
    "col_ind = np.argsort(-preds, axis=1)[:,:5]\n",
    "hc = [' '.join(row.astype(str)) for row in col_ind]\n",
    "\n",
    "sub = pd.DataFrame(data=hc, index=submission.id)\n",
    "sub.reset_index(inplace=True)\n",
    "sub.columns = submission.columns\n",
    "sub.to_csv('./output/pred_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
