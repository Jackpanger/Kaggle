{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Expedia 酒店推荐比赛\n",
    "\n",
    "[link](https://www.kaggle.com/c/expedia-hotel-recommendations/overview)\n",
    "\n",
    "### 问题背景\n",
    "![](./img/kaggle-expedia-hotel-recommendation.png)\n",
    "\n",
    "### 数据描述\n",
    "\n",
    "Expedia has provided you logs of customer behavior. These include what customers searched for, how they interacted with search results (click/book), whether or not the search result was a travel package. The data in this competition is a random selection from Expedia and is not representative of the overall statistics.\n",
    "\n",
    "Expedia is interested in predicting which hotel group a user is going to book. Expedia has in-house algorithms to form hotel clusters, where similar hotels for a search (based on historical price, customer star ratings, geographical locations relative to city center, etc) are grouped together. These hotel clusters serve as good identifiers to which types of hotels people are going to book, while avoiding outliers such as new hotels that don't have historical data.\n",
    "\n",
    "Your goal of this competition is to predict the booking outcome (hotel cluster) for a user event, based on their search and other attributes associated with that user event.\n",
    "\n",
    "The train and test datasets are split based on time: training data from 2013 and 2014, while test data are from 2015. The public/private leaderboard data are split base on time as well. Training data includes all the users in the logs, including both click events and booking events. Test data only includes booking events. \n",
    "\n",
    "destinations.csv data consists of features extracted from hotel reviews text. \n",
    "\n",
    "Note that some srch_destination_id's in the train/test files don't exist in the destinations.csv file. This is because some hotels are new and don't have enough features in the latent space. Your algorithm should be able to handle this missing information.\n",
    "\n",
    "### File descriptions\n",
    "\n",
    "* **train.csv** - the training set\n",
    "* **test.csv** - the test set\n",
    "* **destinations.csv** - hotel search latent attributes\n",
    "* **sample_submission.csv** - a sample submission file in the correct format\n",
    "\n",
    "\n",
    "### Data fields\n",
    "\n",
    "**train/test.csv**\n",
    "\n",
    "![](./img/data.png)\n",
    "\n",
    "### 评估标准与提交格式\n",
    "\n",
    "![](./img/eval.png)\n",
    "\n",
    "### 解法图示\n",
    "\n",
    "![](./img/solution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据泄露处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import datetime\n",
    "from heapq import nlargest # 堆\n",
    "from operator import itemgetter\n",
    "import os\n",
    "\n",
    "\n",
    "# 准备好可以被查找的表\n",
    "def prepare_arrays_match():\n",
    "    f = open(\"./input/train.csv\", \"r\")  # 不要轻易使用pandas去读\n",
    "    f.readline()\n",
    "    \n",
    "    best_hotels_od_ulc = dict()\n",
    "    best_hotels_uid_miss = dict()\n",
    "    best_s00 = dict()\n",
    "    best_s01 = dict()\n",
    "    total = 0\n",
    "\n",
    "    # Calc counts\n",
    "    while 1:\n",
    "        line = f.readline().strip() # 去除左右空格\n",
    "        total += 1\n",
    "\n",
    "        if total % 2000000 == 0:\n",
    "            print('Read {} lines...'.format(total)) # 通知\n",
    "\n",
    "        if line == '':\n",
    "            break # 停止\n",
    "\n",
    "        # 开始解析\n",
    "        arr = line.split(\",\") \n",
    "        #20170624\n",
    "        book_year = int(arr[0][:4])  \n",
    "        book_month = int(arr[0][5:7])\n",
    "        user_location_city = arr[5]\n",
    "        orig_destination_distance = arr[6]\n",
    "        user_id = arr[7]\n",
    "        srch_destination_id = arr[16]\n",
    "        hotel_country = arr[21]\n",
    "        hotel_market = arr[22]\n",
    "        is_booking = float(arr[18])\n",
    "        hotel_cluster = arr[23]\n",
    "\n",
    "        # 创造一些值\n",
    "        append_0 = ((book_year - 2012)*12 + (book_month - 12))\n",
    "        append_1 = append_0 * append_0 * (3 + 17.60*is_booking)\n",
    "        append_2 = 3 + 5.56*is_booking\n",
    "\n",
    "        # 创造key： unique(user_id, user_location_city, srch_destination_id, hotel_country, hotel_market)\n",
    "        if user_location_city != '' and orig_destination_distance != '' and user_id !='' and srch_destination_id != '' and hotel_country != '':\n",
    "            # hash处理\n",
    "            s00 = hash(str(user_id)+':'+str(user_location_city)+':'+str(srch_destination_id)+':'+str(hotel_country)+':'+str(hotel_market))\n",
    "            if s00 in best_s00:\n",
    "                if hotel_cluster in best_s00[s00]:\n",
    "                    best_s00[s00][hotel_cluster] += append_1\n",
    "                else:\n",
    "                    best_s00[s00][hotel_cluster] = append_1\n",
    "            else:\n",
    "                best_s00[s00] = dict()\n",
    "                best_s00[s00][hotel_cluster] = append_1\n",
    "\n",
    "        # 创造key： unique(user_id, srch_destination_id, hotel_country, hotel_market)\n",
    "        if user_location_city != '' and orig_destination_distance != '' and user_id !='' and srch_destination_id != '':\n",
    "            s01 = hash(str(user_id)+':'+str(srch_destination_id)+':'+str(hotel_country)+':'+str(hotel_market))\n",
    "            if s01 in best_s01:\n",
    "                if hotel_cluster in best_s01[s01]:\n",
    "                    best_s01[s01][hotel_cluster] += append_1\n",
    "                else:\n",
    "                    best_s01[s01][hotel_cluster] = append_1\n",
    "            else:\n",
    "                best_s01[s01] = dict()\n",
    "                best_s01[s01][hotel_cluster] = append_1\n",
    "\n",
    "        # 创造key： unique(user_location_city, srch_destination_id, hotel_country, hotel_market)\n",
    "        if user_location_city != '' and orig_destination_distance == '' and srch_destination_id != '' and hotel_country != '':\n",
    "            s0 = hash(str(user_location_city)+':'+str(srch_destination_id)+':'+str(hotel_country)+':'+str(hotel_market))\n",
    "            if s0 in best_hotels_uid_miss:\n",
    "                if hotel_cluster in best_hotels_uid_miss[s0]:\n",
    "                    best_hotels_uid_miss[s0][hotel_cluster] += append_1\n",
    "                else:\n",
    "                    best_hotels_uid_miss[s0][hotel_cluster] = append_1\n",
    "            else:\n",
    "                best_hotels_uid_miss[s0] = dict()\n",
    "                best_hotels_uid_miss[s0][hotel_cluster] = append_1\n",
    "\n",
    "        # 创造key： unique(user_location_city, srch_destination_id)\n",
    "        if user_location_city != '' and orig_destination_distance != '':\n",
    "            s1 = hash(str(user_location_city)+':'+str(orig_destination_distance))\n",
    "\n",
    "            if s1 in best_hotels_od_ulc:\n",
    "                if hotel_cluster in best_hotels_od_ulc[s1]:\n",
    "                    best_hotels_od_ulc[s1][hotel_cluster] += append_0\n",
    "                else:\n",
    "                    best_hotels_od_ulc[s1][hotel_cluster] = append_0\n",
    "            else:\n",
    "                best_hotels_od_ulc[s1] = dict()\n",
    "                best_hotels_od_ulc[s1][hotel_cluster] = append_0\n",
    "\n",
    "    f.close()\n",
    "    return best_s00,best_s01, best_hotels_od_ulc, best_hotels_uid_miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_submission(best_s00, best_s01, best_hotels_od_ulc, best_hotels_uid_miss):\n",
    "    now = datetime.datetime.now()\n",
    "    path = './output/match_pred.csv'\n",
    "    out = open(path, \"w\")\n",
    "    f = open(\"./input/test.csv\", \"r\")\n",
    "    f.readline()\n",
    "    total = 0\n",
    "    total0 = 0\n",
    "    total00 = 0\n",
    "    total1 = 0\n",
    "    out.write(\"id,hotel_cluster\\n\")\n",
    "    \n",
    "    while 1:\n",
    "        line = f.readline().strip()\n",
    "        total += 1\n",
    "\n",
    "        if total % 100000 == 0:\n",
    "            print('Write {} lines...'.format(total))\n",
    "\n",
    "        if line == '':\n",
    "            break\n",
    "\n",
    "        arr = line.split(\",\")\n",
    "        id = arr[0]\n",
    "        user_location_city = arr[6]\n",
    "        orig_destination_distance = arr[7]\n",
    "        user_id = arr[8]\n",
    "        srch_destination_id = arr[17]\n",
    "        hotel_country = arr[20]\n",
    "        hotel_market = arr[21]\n",
    "\n",
    "        out.write(str(id) + ',')\n",
    "        filled = []\n",
    "\n",
    "        s1 = hash(str(user_location_city)+':'+str(orig_destination_distance))\n",
    "        if s1 in best_hotels_od_ulc:\n",
    "            d = best_hotels_od_ulc[s1]\n",
    "            topitems = nlargest(5, sorted(d.items()), key=itemgetter(1))\n",
    "            for i in range(len(topitems)):\n",
    "                if topitems[i][0] in filled:\n",
    "                    continue\n",
    "                if len(filled) == 5:\n",
    "                    break\n",
    "                out.write(' ' + topitems[i][0])\n",
    "                filled.append(topitems[i][0])\n",
    "                total1 += 1\n",
    "\n",
    "        if orig_destination_distance == '':\n",
    "            s0 = hash(str(user_location_city)+':'+str(srch_destination_id)+':'+str(hotel_country)+':'+str(hotel_market))\n",
    "            if s0 in best_hotels_uid_miss:\n",
    "                d = best_hotels_uid_miss[s0]\n",
    "                topitems = nlargest(4, sorted(d.items()), key=itemgetter(1))\n",
    "                for i in range(len(topitems)):\n",
    "                    if topitems[i][0] in filled:\n",
    "                        continue\n",
    "                    if len(filled) == 5:\n",
    "                        break\n",
    "                    out.write(' ' + topitems[i][0])\n",
    "                    filled.append(topitems[i][0])\n",
    "                    total0 += 1\n",
    "\n",
    "        s00 = hash(str(user_id)+':'+str(user_location_city)+':'+str(srch_destination_id)+':'+str(hotel_country)+':'+str(hotel_market))\n",
    "        s01 = hash(str(user_id)+':'+str(srch_destination_id)+':'+str(hotel_country)+':'+str(hotel_market))\n",
    "        if s01 in best_s01 and s00 not in best_s00:\n",
    "            d = best_s01[s01]\n",
    "            topitems = nlargest(4, sorted(d.items()), key=itemgetter(1))\n",
    "            for i in range(len(topitems)):\n",
    "                if topitems[i][0] in filled:\n",
    "                    continue\n",
    "                if len(filled) == 5:\n",
    "                    break\n",
    "                out.write(' ' + topitems[i][0])\n",
    "                filled.append(topitems[i][0])\n",
    "                total00 += 1\n",
    "\n",
    "        out.write(\"\\n\")\n",
    "    out.close()\n",
    "    print('Total 1: {} ...'.format(total1))\n",
    "    print('Total 0: {} ...'.format(total0))\n",
    "    print('Total 00: {} ...'.format(total00))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 2000000 lines...\n",
      "Read 4000000 lines...\n",
      "Read 6000000 lines...\n",
      "Read 8000000 lines...\n",
      "Read 10000000 lines...\n",
      "Read 12000000 lines...\n",
      "Read 14000000 lines...\n",
      "Read 16000000 lines...\n",
      "Read 18000000 lines...\n",
      "Read 20000000 lines...\n",
      "Read 22000000 lines...\n",
      "Read 24000000 lines...\n",
      "Read 26000000 lines...\n",
      "Read 28000000 lines...\n",
      "Read 30000000 lines...\n",
      "Read 32000000 lines...\n",
      "Read 34000000 lines...\n",
      "Read 36000000 lines...\n"
     ]
    }
   ],
   "source": [
    "best_s00,best_s01, best_hotels_od_ulc, best_hotels_uid_miss = prepare_arrays_match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 100000 lines...\n",
      "Write 200000 lines...\n",
      "Write 300000 lines...\n",
      "Write 400000 lines...\n",
      "Write 500000 lines...\n",
      "Write 600000 lines...\n",
      "Write 700000 lines...\n",
      "Write 800000 lines...\n",
      "Write 900000 lines...\n",
      "Write 1000000 lines...\n",
      "Write 1100000 lines...\n",
      "Write 1200000 lines...\n",
      "Write 1300000 lines...\n",
      "Write 1400000 lines...\n",
      "Write 1500000 lines...\n",
      "Write 1600000 lines...\n",
      "Write 1700000 lines...\n",
      "Write 1800000 lines...\n",
      "Write 1900000 lines...\n",
      "Write 2000000 lines...\n",
      "Write 2100000 lines...\n",
      "Write 2200000 lines...\n",
      "Write 2300000 lines...\n",
      "Write 2400000 lines...\n",
      "Write 2500000 lines...\n",
      "Total 1: 1092018 ...\n",
      "Total 0: 1848215 ...\n",
      "Total 00: 244309 ...\n"
     ]
    }
   ],
   "source": [
    "gen_submission(best_s00, best_s01, best_hotels_od_ulc, best_hotels_uid_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
